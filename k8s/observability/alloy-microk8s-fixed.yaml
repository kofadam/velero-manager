apiVersion: v1
kind: ServiceAccount
metadata:
  name: alloy
  namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: alloy
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
      - pods/log
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - apiGroups: [""]
    resources:
      - namespaces
    verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: alloy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: alloy
subjects:
  - kind: ServiceAccount
    name: alloy
    namespace: observability
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: observability
data:
  config.alloy: |
    // ============================================
    // METRICS COLLECTION FOR VELERO-MANAGER
    // ============================================

    // Scrape Velero Manager metrics
    prometheus.scrape "velero_manager" {
      targets = [
        {
          "__address__" = "velero-manager.velero-manager.svc.cluster.local:80",
          "__metrics_path__" = "/metrics",
          "job" = "velero-manager",
        },
      ]
      forward_to = [prometheus.remote_write.microk8s.receiver]
      scrape_interval = "30s"
    }

    // Send metrics to existing MicroK8s Prometheus
    prometheus.remote_write "microk8s" {
      endpoint {
        url = "http://kube-prom-stack-kube-prome-prometheus.observability.svc.cluster.local:9090/api/v1/write"
      }
    }

    // ============================================
    // LOG COLLECTION - SIMPLIFIED
    // ============================================

    // Discover pods in velero and velero-manager namespaces
    discovery.kubernetes "pods" {
      role = "pod"
      namespaces {
        names = ["velero", "velero-manager"]
      }
    }

    // Add labels to discovered pods
    discovery.relabel "pods" {
      targets = discovery.kubernetes.pods.targets

      // Add namespace label
      rule {
        source_labels = ["__meta_kubernetes_namespace"]
        target_label = "namespace"
      }

      // Add pod name label
      rule {
        source_labels = ["__meta_kubernetes_pod_name"]
        target_label = "pod"
      }

      // Add container name label
      rule {
        source_labels = ["__meta_kubernetes_pod_container_name"]
        target_label = "container"
      }

      // Add app label
      rule {
        source_labels = ["__meta_kubernetes_pod_label_app"]
        target_label = "app"
      }

      // Set log path for container runtime
      rule {
        source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
        target_label = "__path__"
        separator = "/"
        replacement = "/var/log/pods/*$1/*.log"
      }
    }

    // Collect logs from Kubernetes pods
    loki.source.kubernetes "pods" {
      targets    = discovery.relabel.pods.output
      forward_to = [loki.process.all_logs.receiver]
    }

    // Process all logs with basic parsing
    loki.process "all_logs" {
      forward_to = [loki.write.microk8s.receiver]

      // Parse Gin framework logs (for velero-manager)
      stage.regex {
        expression = `\[GIN\]\s+(?P<timestamp>\d{4}/\d{2}/\d{2}\s+-\s+\d{2}:\d{2}:\d{2})\s+\|\s+(?P<status_code>\d{3})\s+\|\s+(?P<duration>[^\s]+)\s+\|\s+(?P<client_ip>[^\s]+)\s+\|\s+(?P<method>\w+)\s+"(?P<path>[^"]+)"`
      }

      // Parse Velero structured logs
      stage.regex {
        expression = `time="(?P<velero_timestamp>[^"]+)"\s+level=(?P<level>\w+)\s+msg="(?P<message>[^"]+)"`
      }

      // Extract general log levels
      stage.regex {
        expression = `(?P<detected_level>(ERROR|WARN|INFO|DEBUG|error|warn|info|debug|Failed|Completed))`
      }

      // Extract backup/restore operations
      stage.regex {
        expression = `(?P<operation>backup|restore)=?(?P<operation_name>[\w-]+)`
      }

      // Add labels for extracted fields
      stage.labels {
        values = {
          level = "",
          detected_level = "",
          method = "",
          status_code = "",
          path = "",
          operation = "",
          operation_name = "",
        }
      }

      // Set severity based on content
      stage.match {
        selector = '{detected_level=~"ERROR|error|Failed"}'
        stages = {
          stage.static_labels {
            values = {
              severity = "error",
            }
          }
        }
      }

      stage.match {
        selector = '{detected_level=~"WARN|warn"}'
        stages = {
          stage.static_labels {
            values = {
              severity = "warning",
            }
          }
        }
      }

      stage.match {
        selector = '{detected_level=~"INFO|info|Completed"}'
        stages = {
          stage.static_labels {
            values = {
              severity = "info",
            }
          }
        }
      }

      // Add static labels
      stage.static_labels {
        values = {
          cluster = env("CLUSTER_NAME"),
          job = "velero-logs",
        }
      }
    }

    // Write logs to existing MicroK8s Loki
    loki.write "microk8s" {
      endpoint {
        url = "http://loki.observability.svc.cluster.local:3100/loki/api/v1/push"
      }
      external_labels = {}
    }

    // ============================================
    // SELF-MONITORING
    // ============================================

    prometheus.exporter.self "alloy" {}

    prometheus.scrape "alloy_self" {
      targets = prometheus.exporter.self.alloy.targets
      forward_to = [prometheus.remote_write.microk8s.receiver]
      scrape_interval = "60s"
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: alloy
  namespace: observability
  labels:
    app: alloy
spec:
  selector:
    matchLabels:
      app: alloy
  template:
    metadata:
      labels:
        app: alloy
    spec:
      serviceAccountName: alloy
      hostPID: true
      hostNetwork: false
      dnsPolicy: ClusterFirst
      containers:
        - name: alloy
          image: grafana/alloy:v1.4.2
          args:
            - run
            - /etc/alloy/config.alloy
            - --server.http.listen-addr=0.0.0.0:12345
            - --storage.path=/var/lib/alloy
          env:
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CLUSTER_NAME
              value: "microk8s-test"
          ports:
            - containerPort: 12345
              name: http-metrics
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
            - name: varlog
              mountPath: /var/log
              readOnly: true
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
            - name: data
              mountPath: /var/lib/alloy
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
            limits:
              cpu: 500m
              memory: 500Mi
          securityContext:
            runAsUser: 0
            privileged: true
      volumes:
        - name: config
          configMap:
            name: alloy-config
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: data
          hostPath:
            path: /var/lib/alloy
            type: DirectoryOrCreate
---
apiVersion: v1
kind: Service
metadata:
  name: alloy
  namespace: observability
  labels:
    app: alloy
spec:
  type: ClusterIP
  ports:
    - port: 12345
      targetPort: 12345
      protocol: TCP
      name: http-metrics
  selector:
    app: alloy
